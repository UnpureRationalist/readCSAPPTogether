# 第九章

## 1、虚拟内存

虚拟内存是硬件异常、硬件地址翻译、主存、磁盘文件和内核软件的完美交互，它为每个进程提供了一个大的、 一致的和私有的地址空间。虚拟内存提供了三个重要的能力： 

- 它将主存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据。
- 它为每个进程提供了一致的地址空间，从而简化了内存管理。
- 它保护了每个进程的地址空间不被其他进程破坏。

虚拟内存是一个实际上不存在的内存系统，它的每个内存页实际上是到物理内存或磁盘的映射。

### 页表

操作系统为每个进程提供一个独立的页表，**页表将虚拟页映射到物理页**，虚拟地址空间中的每个页在页表中一个固定偏移量处有一个页表条目（PTE）。我们假设每个 PTE 由一个地址有效位和一个 n 位地址字段组成，有效位表明该虚拟页当前是否缓存在 DRAM 中，根据有效位和地址字段的不同，可以将 PTE 分为以下三类：

- 有效位为 0，地址字段为空：虚拟系统还未分配的页，它不会占据任何内存或磁盘的空间。
- 有效位为 0，地址字段不空：未缓存在物理内存中的已分配页，目前存放在磁盘上。
- 有效位为 1：当前已缓存在物理内存中的已分配页。

![image](https://user-images.githubusercontent.com/56211928/147178169-21d50c4e-d522-4bf8-bdab-0a7d5ec8db62.png)

### 地址翻译

CPU 芯片中有专门负责地址翻译的硬件 MMU，CPU 读取进程指令中的虚拟地址，**地址翻译硬件将虚拟地址作为一个索引到页表中查询**，如果页表对应项设置了有效位，则表示该地址的数据已经缓存在内存中，在内存中的物理地址是该页表项的地址字段，CPU 可以到内存（高速缓存）的相应位置读取内容。否则，会触发缺页异常。缺页异常调用内核中的缺页异常处理程序，该程序会选择根据某种策略，选择物理内存中的一页，将页表地址字段对应的磁盘上的内容调入内存中，并修改页表的对应项。下图展示 MMU 如何利用页表进行地址翻译：

![image](https://user-images.githubusercontent.com/56211928/147181803-d4c3078c-70c4-4182-adc6-74e82b1355cc.png)

CPU 中的一个控制寄存器——页表基址寄存器指向当前页表，n 位的虚拟地址包含两部分，一个 p 位的虚拟页面偏移和一个 n - p 位的虚拟页号，MMU 利用 VPN 来选择适当的页表项（PTE），将 PPN 和 VPO 串联起来，就得到相应的物理地址。

现代操作系统使用按需页面调度的方式，即不会预先从磁盘读取内容到内存，直到发生缺页时才进行调度。局部性原则保证了在任意时刻，程序将趋向于在一个较小的活动页面集合上工作，这个集合叫做工作集或常驻集合。通常，一个程序在稳定状态下不会出现大量的缺页现象。

### 快表（TLB）

每次 CPU 产生一个虚拟地址， MMU 就必须查阅一个 PTE，以便将虚拟地址翻译为物理地址。在最糟糕的情况下，这会要求从内存多取一次数据，代价是几十到几百个周期。许多系统都试图消除这样的开销，它们在 MMU 中包括了一个关于 PTE 的小的缓存，称为翻译后备缓冲器（TLB）。TLB 是一个虚拟寻址的缓存，原理与 cache 相同，它每一行保存着一个由单个页表项（PTE）组成的块（cache 中每项保存固定大小的内存块，通常是 64 字节）。

### 多级页表

多级页表用来压缩页表大小。这种方法从两个方面减少了内存要求（假设一个具有二级页表的系统）。

- 第一，如果一级页表中的一个 PTE 是空的，那么相应的二级页表就根本不会存在，这是一种巨大的潜在节约。
- 第二，只有一级页表才需要总是在主存中，虚拟内存系统可以在需要时创建、调入或调出二级页表，这就减少了主存的压力，只有最经常使用的二级页表才需要缓存在内存中。

一个具有 k 级页表层次结构的示意图如下：

![image](https://user-images.githubusercontent.com/56211928/147185326-bdda256f-a415-4de3-82e0-d2283899224e.png)

虚拟地址被划分成为 k 个 VPN 和 1 个 VPO。每个 VPN i 都是一个到第 i 级页表的索引。第 j 级页表中的每PTE, 都指向第 j + 1 级的某个页表的基址（第 1 级页表的基址由页表基址寄存器给出）。第 k 级页表中的每个 PTE 包含某个物理页面的实际地址 PPN, 或者一个磁盘块的地址。为了构造物理地址，在能够确定 PPN之前，MMU 必须访问 k 个 PTE。但由于 TLB 的存在，这种代价是可以接收的。

### Linux 虚拟内存

Linux 为每个进程维护一个单独的虚拟地址空间，如下图：

![image](https://user-images.githubusercontent.com/56211928/147191146-9aaa9b0a-dbf4-430f-a1e3-a6bc721b55d6.png)

内核虚拟内存包含内核中的代码和数据结构，内核虚拟内存的某些区域被映射到所有进程共享的物理页面，即不同进程的虚拟内存映射到同样的物理内存中。例如，每个进程共享内核的代码和全局数据结构。内核虚拟内存的其他区域包含每个进程都不相同的数据。比如说页表、内核在进程的上下文中执行代码时使用的栈，以及记录虚拟地址空间当前组织的各种数据结构。

内核为系统中的每个进程维护一个单独的任务结构 task_struct。任务结构中的元素包含或者指向内核运行该进程所需要的所有信息（例如 PID、指向用户栈的指针、可执行目标文件的名字，以及程序计数器）。当 MMU 在翻译某个虚拟地址时发生了缺页，内核的缺页处理程序将通过 task_struct 中的某些数据（mm_struct 中的 mmap）判断该虚拟地址是否合法（该虚拟地址是否在某个结构定义的区域内，访存权限的判断）。

## 2、内存映射

Linux 通过将一个虚拟内存区域与一个磁盘上的对象关联起来，以初始化这个虚拟内存区域的内容，这个过程称为内存映射。

### 共享对象与私有对象

一个对象可以被映射到虚拟内存的一个区域，要么作为共享对象，要么作为私有对象。如果一个进程将一个共享对象映射到它的虚拟地址空间的一个区域内，那么这个进程对这个区域的任何写操作，对于那些也把这个共享对象映射到它们虚拟内存的其他进程而言，也是可见的。另一方面，对于一个映射到私有对象的区域做的改变，对于其他进程来说是不可见的。

当一个对象被映射到了多个共享区域，物理内存中只需要存放共享对象的一个副本。私有对象使用写时复制的技术。当两个或多个进程同时使用同一个私有对象时，物理内存中也同样只保存一份副本。对于每个映射私有对象的进程，相应私有区域的页表条目都被标记为只读，并且区域结构被标记为私有的写时复制。只要没有进程试图写它自己的私有区域，它们就可以继续共享物理内存中对象的一个单独副本。然而，只要有一个进程试图写私有区域内的某个页面，那么这个写操作就会触发一个保护故障。当故障处理程序注意到保护异常是由于进程试图写私有的写时复制区域中的一个页面而引起的，它就会在物理内存中创建这个页面的一个新副本，更新页表条目指向这个新的副本，然后恢复这个页面的可写权限，当故障处理程序返回时， CPU 重新执行这个写操作，现在在新创建的页面上这个写操作就可以正常执行了。

![image](https://user-images.githubusercontent.com/56211928/147212557-3b921dc9-2311-4edd-a9cb-37abd3e20b48.png)

通过延迟私有对象中的副本直到最后可能的时刻，写时复制最充分地使用了稀有的物理内存。

### 程序的创建与加载

**Linux 使用 fork + execve 函数来创建并加载进程**。

fork 函数用来在当前进程下创建子进程。

fork 函数被当前进程调用时，内核为新进程创建各种数据结构，并分配给它一个唯一的 PID。为了给这个新进程创建虚拟内存，它创建了当前进程的 mm_struct、区域结构和页表的原样副本。它将两个进程中的每个页面都标记为只读，并将两个进程中的每个区域结构都标记为私有的写时复制。**fork 在新进程中返回时，新进程现在的虚拟内存刚好和调用 fork 时存在的虚拟内存相同**。当这两个进程中的任一个后来进行写操作时，写时复制机制就会创建新页面。因此，也就为每个进程保持了私有地址空间的抽象概念。

execve 函数在当前进程中加载并运行可执行目标文件，该函数的执行需要以下几个步骤：

- 删除已存在的用户区域：删除当前进程虚拟地址的用户部分中的已存在的区域结构。
- 映射私有区域：为新程序的代码、数据、bss 和栈区域创建新的区域结构。所有这些新的区域都是私有的、写时复制的。代码和数据区域被映射为可执行文件中的 .text 和 .data 区。 bss 区域是请求二进制零的，映射到匿名文件，栈和堆区域也是请求二进制零的，初始长度为零。
- 映射共享区域：如果可执行文件与共享对象（或目标）链接，比如标准 libc.so，那么这些对象都是动态链接到这个程序的，然后再映射到用户虚拟地址空间中的共享区域内。
- 设置程序计数器 (PC) ：execve 做的最后一件事情就是设置当前进程上下文中的程序计数器，使之指向代码区域的入口点就，即 \_start 函数的地址，该（虚拟）地址在可执行文件的头部信息中给出。

下一次调度这个进程时，它将从这个入口点开始执行 Linux 将根据需要换入代码和数据页面。

![image](https://user-images.githubusercontent.com/56211928/147213751-b31960cc-2a0d-4e48-85a2-df89a44af2c9.png)

## 3、动态分配内存

动态内存分配器维护着一个进程的虚拟内存区域，称为堆。它紧接在未初始化的数据区域后开始，并向上生长（向更高的地址）对于每个进程，内核维护着一个变量 brk，它指向堆的顶部。分配器将堆视为一组不同大小的块的集合来维护，每个块就是一个连续的虚拟内存片，要么是已分配的，要么是空闲的。

分配器有两种基本风格，两种风格都要求应用显式地分配块。它们的不同之处在于由谁来负责释放已分配的块。

- 显式分配器：要求应用显式地释放任何已分配的块。例如，C 标准库提供一种叫做 malloc 程序包的显式分配器。程序通过调用 malloc 函数来分配一个块，并通过调用 free 函数来释放一个块。 C++ 中的 new 和 delete 操作符与 C 中的 malloc 和 free 相当。
- 隐式分配器：要求分配器检测一个已分配块何时不再被程序所使用，并释放这个块。隐式分配器也叫做垃圾收集器。诸如 Lisp、ML 以及 Java 之类的高级语言就依赖垃圾收集来释放已分配的块。

### 碎片

造成堆利用率很低的主要原因是一种称为碎片的现象，当虽然有未使用的内存但不能用来满足分配请求时，就发生这种现象。有两种形式的碎片：内部碎片和外部碎片。

- 内部碎片是在一个已分配块比有效载荷大时发生的。很多原因都可能造成这个问题。例如，一个分配器的实现可能对已分配块强加一个最小的大小值，而这个大小要比某个请求的有效载荷大。或者，分配器可能增加块大小以满足对齐约束条件。
- 外部碎片是当空闲内存合计起来足够满足一个分配请求，但是没有一个单独的空闲块足够大可以来处理这个请求时发生的。

内部碎片的量化是简单明了的。它就是已分配块大小和它们的有效载荷大小之差的和。因此，在任意时刻，内部碎片的数最只取决于以前请求的模式和分配器的实现方式。外部碎片比内部碎片的量化要困难得多，因为它不仅取决于以前请求的模式和分配器的实现方式，还取决于将来请求的模式。因为外部碎片难以量化且不可能预测，所以分配器通常采用启发式策略来试图维持少量的大空闲块，而不是维持大蜇的小空闲块。

### 空闲链表

一种流行的减少分配时间的方法，叫做分离存储，就是维护多个空闲链表，其中每个链表中的块有大致相等的大小。分配器维护着一个空闲链表数组，每个大小类一个空闲链表，按照大小的升序排列。当分配器需要一个大小为 n 的块时，它就搜索相应的空闲链表。如果不能找到合适的块与之匹配，它就搜索下一个链表，以此类推。

C 语言标准库中的 malloc 采用分离适配的分配方法。分配器维护着一个空闲链表的数组。每个空闲链表和一个大小类相关联。为了分配一个块，必须确定请求的大小类，并且对适当的空闲链表做首次适配，如果这个空闲链表中有空闲块，那么就（可选地）分割它，并将剩余的部分插入到适当的空闲链表中。如果找不到合适的块，那么就搜索下一个更大的大小类的空闲链表。如此重复，直到找到一个合适的块。如果空闲链表中没有合适的块，那么就向操作系统请求额外的堆内存，从这个新的堆内存中分配出一个块，将剩余部分放置在适当的大小类中。要释放一个块，我们执行合并，并将结果放置到相应的空闲链表中。

伙伴系统是分离适配的一种特例，其中每个大小类都是 2 的幂。基本思路是假设一个堆的大小为 2<sup>m</sup> 个字，我们为每个块大小 2<sup>k</sup> 维护一个分离空闲链表，其中 0 ≤ k ≤ m。请求块大小向上舍入到最接近的 2 的幂。最开始时，只有一个大小为 2<sup>m</sup> 个字的空闲块。为了分配一个大小为 2<sup>k</sup> 的块，我们找到第一个可用的、大小为 2<sup>j</sup> 的块，其中 k ≤ j ≤ m。如果 j = k，那么我们就完成了。否则，我们递归地二分割这个块，直到 j = k 。当我们进行这样的分割时，每个剩下的半块（也叫做伙伴）被放置在相应的空闲链表中。要释放一个大小为 2<sup>k</sup> 的块，我们继续合并空闲的伙伴。当遇到一个已分配的伙伴时，我们就停止合并。


